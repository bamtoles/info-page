import streamlit as st
import google.generativeai as genai
import os, sys

st.set_page_config(page_title="ê³ ê° ì‘ëŒ€ ì±—ë´‡", page_icon="ğŸ›ï¸")
st.title("ê³ ê° ì‘ëŒ€ ì±—ë´‡ (Gemini + Streamlit)")

# 1) API í‚¤
API_KEY = st.secrets.get("GEMINI_API_KEY") or os.environ.get("GEMINI_API_KEY")
if not API_KEY:
    st.error("GEMINI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Streamlit Cloud Secretsì— ì¶”ê°€í•˜ì„¸ìš”.")
    st.stop()

# 2) ì„¤ì • & ë²„ì „ í‘œì‹œ
genai.configure(api_key=API_KEY)
st.sidebar.write(f"google-generativeai: **{genai.__version__}**")

# 3) í˜„ì¬ í‚¤ë¡œ ê°€ëŠ¥í•œ ëª¨ë¸ë“¤(= generateContent ì§€ì›) ì¡°íšŒ
with st.sidebar.expander("ğŸ” ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡", expanded=False):
    try:
        available = [m for m in genai.list_models() if "generateContent" in getattr(m, "supported_generation_methods", [])]
        for m in available:
            st.write(m.name, m.supported_generation_methods)
    except Exception as e:
        st.error(f"ëª¨ë¸ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        st.stop()

# 4) ì„ í˜¸ ëª¨ë¸ ìë™ ì„ íƒ(1.5-flash ìš°ì„  â†’ pro â†’ ë‚˜ë¨¸ì§€)
def pick_model_name(models):
    # ì´ë¦„ì€ 'models/...' í˜•ì‹ì¼ ìˆ˜ ìˆìœ¼ë‹ˆ ê·¸ëŒ€ë¡œ ì“°ë˜, í•„ìš”í•˜ë©´ ì ‘ë‘ì‚¬ ì œê±°í•´ë„ ë©ë‹ˆë‹¤.
    def find(substr):
        return next((m.name for m in models if substr in m.name), None)
    return find("1.5-flash") or find("1.5-pro") or (models[0].name if models else None)

picked = pick_model_name(available)
if not picked:
    st.error("generateContentë¥¼ ì§€ì›í•˜ëŠ” ëª¨ë¸ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. í‚¤ ì¢…ë¥˜/ê¶Œí•œì„ í™•ì¸í•˜ì„¸ìš”.")
    st.stop()

# (ì„ íƒ) ì‚¬ì´ë“œë°”ì—ì„œ ìˆ˜ë™ ì„ íƒë„ ê°€ëŠ¥
model_name = st.sidebar.selectbox("ì‚¬ìš©í•  ëª¨ë¸", options=[m.name for m in available], index=[m.name for m in available].index(picked))

SYSTEM_PROMPT = """
ë‹¹ì‹ ì€ ì•„ë˜ ê¸°ì¤€ì— ë”°ë¼ ë‹µë³€í•˜ëŠ” ê³ ê° ì‘ëŒ€ìš© AI ì±—ë´‡ì…ë‹ˆë‹¤.
--- [ì°¸ê³  ê¸°ì¤€ ì‹œì‘] ---
1) ì •ì¤‘í•˜ê³  ê³µê° ì–´ë¦° ë§íˆ¬ë¡œ ì‘ë‹µ
2) ë¶ˆí¸ ì‚¬í•­ì„ êµ¬ì²´ì ìœ¼ë¡œ ì •ë¦¬(ë¬´ì—‡/ì–¸ì œ/ì–´ë””ì„œ/ì–´ë–»ê²Œ) â†’ ë‹´ë‹¹ì ì „ë‹¬ ì•ˆë‚´
3) ëì— ì´ë©”ì¼ ì£¼ì†Œ ìš”ì²­. ê±°ë¶€ ì‹œ â€œì—°ë½ì²˜ ì •ë³´ê°€ ì—†ì–´ ê²€í†  ê²°ê³¼ë¥¼ ì „ë‹¬ë“œë¦´ ìˆ˜ ì—†ì–´ìš”â€ ê³ ì§€
--- [ì°¸ê³  ê¸°ì¤€ ë] ---
ì¶”ì¸¡í•˜ê±°ë‚˜ ì‚¬ì‹¤ì´ ì•„ë‹Œ ë‚´ìš©ì€ ë§í•˜ì§€ ë§ˆì„¸ìš”.
"""

# ëª¨ë¸ ìƒì„±: ì´ë¦„ì— 'models/' ì ‘ë‘ì‚¬ê°€ í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš© ê°€ëŠ¥
model = genai.GenerativeModel(model_name=model_name, system_instruction=SYSTEM_PROMPT)

# ì´í•˜ ê¸°ì¡´ ë¡œì§ ìœ ì§€
if "chat" not in st.session_state:
    st.session_state.chat = model.start_chat(history=[])
if "messages" not in st.session_state:
    st.session_state.messages = []

st.success("ì–´ë–¤ ì ì´ ë¶ˆí¸í•˜ì…¨ëŠ”ì§€ ì•Œë ¤ì£¼ì„¸ìš”.")

for role, text in st.session_state.messages:
    with st.chat_message("ai" if role == "ai" else "user"):
        st.markdown(text)

user_msg = st.chat_input("ë¶ˆí¸/ìš”ì²­ ì‚¬í•­ì„ ì…ë ¥í•˜ì„¸ìš”")
if user_msg:
    st.session_state.messages.append(("user", user_msg))
    with st.chat_message("user"):
        st.markdown(user_msg)
    with st.chat_message("ai"):
        try:
            resp = st.session_state.chat.send_message(user_msg)
            bot_text = resp.text
            st.session_state.messages.append(("ai", bot_text))
            st.markdown(bot_text)
        except Exception as e:
            st.error(f"ì˜¤ë¥˜: {e}")

if st.sidebar.button("ğŸ§¹ ëŒ€í™” ì´ˆê¸°í™”"):
    st.session_state.messages = []
    st.session_state.chat = model.start_chat(history=[])
    st.rerun()
