import streamlit as st
import google.generativeai as genai
import os

st.set_page_config(page_title="ê³ ê° ì‘ëŒ€ ì±—ë´‡", page_icon="ğŸ›ï¸")
st.title("ê³ ê° ì‘ëŒ€ ì±—ë´‡ (Gemini + Streamlit)")
st.caption("ì •ì¤‘ ì‘ëŒ€ Â· ë¶ˆí¸ ìˆ˜ì§‘ Â· ë‹´ë‹¹ì ì „ë‹¬ Â· ì´ë©”ì¼ ìˆ˜ì§‘")

# --- 1) API í‚¤ ë¶ˆëŸ¬ì˜¤ê¸° (secrets > env > ì…ë ¥ ë°±ì—…) ---
API_KEY = st.secrets.get("GEMINI_API_KEY") or os.environ.get("GEMINI_API_KEY")
if not API_KEY:
    with st.expander("ğŸ” API í‚¤ê°€ ì—†ë‚˜ìš”? ì—¬ê¸°ë¥¼ ëˆŒëŸ¬ ì„ì‹œ ì…ë ¥"):
        API_KEY = st.text_input("Gemini API í‚¤", type="password")
    if not API_KEY:
        st.info("`.streamlit/secrets.toml` ë˜ëŠ” ë°°í¬ í™˜ê²½ì˜ Secretsì— GEMINI_API_KEYë¥¼ ì €ì¥í•˜ë©´ ìë™ìœ¼ë¡œ ì¸ì‹ë©ë‹ˆë‹¤.")
        st.stop()

# --- 2) Gemini ì„¤ì • ---
try:
    genai.configure(api_key=API_KEY)
except Exception as e:
    st.error(f"API í‚¤ ì„¤ì • ì˜¤ë¥˜: {e}")
    st.stop()

# --- 3) ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì •ì˜ ---
SYSTEM_PROMPT = """
ë‹¹ì‹ ì€ ì•„ë˜ ê¸°ì¤€ì— ë”°ë¼ ë‹µë³€í•˜ëŠ” ê³ ê° ì‘ëŒ€ìš© AI ì±—ë´‡ì…ë‹ˆë‹¤.

--- [ì°¸ê³  ê¸°ì¤€ ì‹œì‘] ---
1) ì‚¬ìš©ìëŠ” ì‡¼í•‘ëª° êµ¬ë§¤ ê³¼ì •ì—ì„œ ê²ªì€ ë¶ˆí¸/ë¶ˆë§Œì„ ì–¸ê¸‰í•©ë‹ˆë‹¤. ì •ì¤‘í•˜ê³  ê³µê° ì–´ë¦° ë§íˆ¬ë¡œ ì‘ë‹µí•˜ì„¸ìš”.
2) ì‚¬ìš©ìì˜ ë¶ˆí¸ ì‚¬í•­ì„ êµ¬ì²´ì ìœ¼ë¡œ ì •ë¦¬í•˜ì—¬(ë¬´ì—‡ì´/ì–¸ì œ/ì–´ë””ì„œ/ì–´ë–»ê²Œ) ìˆ˜ì§‘í•˜ê³ , ì´ë¥¼ ê³ ê° ì‘ëŒ€ ë‹´ë‹¹ìì—ê²Œ ì „ë‹¬í•œë‹¤ëŠ” ì·¨ì§€ë¡œ ì•ˆë‚´í•˜ì„¸ìš”.
3) ë§ˆì§€ë§‰ì—ëŠ” ë‹´ë‹¹ì í™•ì¸ í›„ íšŒì‹ ì„ ìœ„í•´ ì´ë©”ì¼ ì£¼ì†Œë¥¼ ìš”ì²­í•˜ì„¸ìš”.
   - ì‚¬ìš©ìê°€ ì—°ë½ ì œê³µì„ ì›ì¹˜ ì•Šìœ¼ë©´: 
     "ì£„ì†¡í•˜ì§€ë§Œ, ì—°ë½ì²˜ ì •ë³´ë¥¼ ë°›ì§€ ëª»í•˜ì—¬ ë‹´ë‹¹ìì˜ ê²€í†  ë‚´ìš©ì„ ë°›ìœ¼ì‹¤ ìˆ˜ ì—†ì–´ìš”."ë¼ê³  ì •ì¤‘íˆ ê³ ì§€í•˜ì„¸ìš”.
--- [ì°¸ê³  ê¸°ì¤€ ë] ---

ë°˜ë“œì‹œ ìœ„ ê¸°ì¤€ì„ ë”°ë¥´ë©°, ì¶”ì¸¡í•˜ê±°ë‚˜ ì‚¬ì‹¤ì´ ì•„ë‹Œ ë‚´ìš©ì€ ë§í•˜ì§€ ë§ˆì„¸ìš”.
"""

# --- 4) ëª¨ë¸/ì„¸ì…˜ ì´ˆê¸°í™” ---
@st.cache_resource(show_spinner=False)
def _get_model():
    return genai.GenerativeModel(
        model_name="gemini-1.5-flash",
        system_instruction=SYSTEM_PROMPT
    )

model = _get_model()

if "chat" not in st.session_state:
    st.session_state.chat = model.start_chat(history=[])
if "messages" not in st.session_state:
    st.session_state.messages = []  # [(role, text)]

st.success("ì–´ë–¤ ì ì´ ë¶ˆí¸í•˜ì…¨ëŠ”ì§€ ì•Œë ¤ì£¼ì„¸ìš”. ê°€ëŠ¥í•œ í•œ ìì„¸íˆ ë„ì™€ë“œë¦´ê²Œìš”.")

# --- 5) ê³¼ê±° ëŒ€í™” í‘œì‹œ ---
for role, text in st.session_state.messages:
    with st.chat_message("ai" if role == "ai" else "user"):
        st.markdown(text)

# --- 6) ì…ë ¥ì°½ ---
user_msg = st.chat_input("ë¶ˆí¸/ìš”ì²­ ì‚¬í•­ì„ ì…ë ¥í•˜ì„¸ìš”")
if user_msg:
    st.session_state.messages.append(("user", user_msg))
    with st.chat_message("user"):
        st.markdown(user_msg)

    with st.chat_message("ai"):
        with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
            try:
                resp = st.session_state.chat.send_message(user_msg)
                bot_text = resp.text
                st.session_state.messages.append(("ai", bot_text))
                st.markdown(bot_text)
            except Exception as e:
                err = str(e)
                if "400" in err and "prompt" in err.lower():
                    st.error("ìš”ì²­ í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ê¹ë‹ˆë‹¤(í† í° ì œí•œ). ë‚´ìš©ì„ ì¡°ê¸ˆ ì¤„ì—¬ ì£¼ì„¸ìš”.")
                else:
                    st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

# --- 7) ë¦¬ì…‹ ë²„íŠ¼ ---
cols = st.columns(2)
with cols[0]:
    if st.button("ğŸ§¹ ëŒ€í™” ì´ˆê¸°í™”"):
        st.session_state.messages = []
        st.session_state.chat = model.start_chat(history=[])
        st.rerun()
with cols[1]:
    st.caption("TIP: ì´ë©”ì¼ ì£¼ì†ŒëŠ” ë§ˆì§€ë§‰ì— ê¼­ ë‚¨ê²¨ ì£¼ì„¸ìš”.")
